
<h1>numpy.cov<a class="headerlink" href="#numpy-cov" title="Permalink to this heading">#</a></h1>
<dl class="py function">
<dt class="sig sig-object py" id="numpy.cov">
<span class="sig-prename descclassname"><span class="pre">numpy.</span></span><span class="sig-name descname"><span class="pre">cov</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">m</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rowvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ddof</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fweights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aweights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/numpy/numpy/blob/v1.24.0/numpy/lib/function_base.py#L2487-L2706"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#numpy.cov" title="Permalink to this definition">#</a></dt>
<dd><p>Estimate a covariance matrix, given data and weights.</p>
<p>Covariance indicates the level to which two variables vary together.
If we examine N-dimensional samples, <span class="math notranslate nohighlight">\(X = [x_1, x_2, ... x_N]^T\)</span>,
then the covariance matrix element <span class="math notranslate nohighlight">\(C_{ij}\)</span> is the covariance of
<span class="math notranslate nohighlight">\(x_i\)</span> and <span class="math notranslate nohighlight">\(x_j\)</span>. The element <span class="math notranslate nohighlight">\(C_{ii}\)</span> is the variance
of <span class="math notranslate nohighlight">\(x_i\)</span>.</p>
<p>See the notes for an outline of the algorithm.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>m</strong><span class="classifier">array_like</span></dt><dd><p>A 1-D or 2-D array containing multiple variables and observations.
Each row of <em class="xref py py-obj">m</em> represents a variable, and each column a single
observation of all those variables. Also see <em class="xref py py-obj">rowvar</em> below.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array_like, optional</span></dt><dd><p>An additional set of variables and observations. <em class="xref py py-obj">y</em> has the same form
as that of <em class="xref py py-obj">m</em>.</p>
</dd>
<dt><strong>rowvar</strong><span class="classifier">bool, optional</span></dt><dd><p>If <em class="xref py py-obj">rowvar</em> is True (default), then each row represents a
variable, with observations in the columns. Otherwise, the relationship
is transposed: each column represents a variable, while the rows
contain observations.</p>
</dd>
<dt><strong>bias</strong><span class="classifier">bool, optional</span></dt><dd><p>Default normalization (False) is by <code class="docutils literal notranslate"><span class="pre">(N</span> <span class="pre">-</span> <span class="pre">1)</span></code>, where <code class="docutils literal notranslate"><span class="pre">N</span></code> is the
number of observations given (unbiased estimate). If <em class="xref py py-obj">bias</em> is True,
then normalization is by <code class="docutils literal notranslate"><span class="pre">N</span></code>. These values can be overridden by using
the keyword <code class="docutils literal notranslate"><span class="pre">ddof</span></code> in numpy versions &gt;= 1.5.</p>
</dd>
<dt><strong>ddof</strong><span class="classifier">int, optional</span></dt><dd><p>If not <code class="docutils literal notranslate"><span class="pre">None</span></code> the default value implied by <em class="xref py py-obj">bias</em> is overridden.
Note that <code class="docutils literal notranslate"><span class="pre">ddof=1</span></code> will return the unbiased estimate, even if both
<em class="xref py py-obj">fweights</em> and <em class="xref py py-obj">aweights</em> are specified, and <code class="docutils literal notranslate"><span class="pre">ddof=0</span></code> will return
the simple average. See the notes for the details. The default value
is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.5.</span></p>
</div>
</dd>
<dt><strong>fweights</strong><span class="classifier">array_like, int, optional</span></dt><dd><p>1-D array of integer frequency weights; the number of times each
observation vector should be repeated.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.10.</span></p>
</div>
</dd>
<dt><strong>aweights</strong><span class="classifier">array_like, optional</span></dt><dd><p>1-D array of observation vector weights. These relative weights are
typically large for observations considered “important” and smaller for
observations considered less “important”. If <code class="docutils literal notranslate"><span class="pre">ddof=0</span></code> the array of
weights can be used to assign probabilities to observation vectors.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.10.</span></p>
</div>
</dd>
<dt><strong>dtype</strong><span class="classifier">data-type, optional</span></dt><dd><p>Data-type of the result. By default, the return data-type will have
at least <a class="reference internal" href="../arrays.scalars.html#numpy.float64" title="numpy.float64"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.float64</span></code></a> precision.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.20.</span></p>
</div>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>out</strong><span class="classifier">ndarray</span></dt><dd><p>The covariance matrix of the variables.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="numpy.corrcoef.html#numpy.corrcoef" title="numpy.corrcoef"><code class="xref py py-obj docutils literal notranslate"><span class="pre">corrcoef</span></code></a></dt><dd><p>Normalized covariance matrix</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>Assume that the observations are in the columns of the observation
array <em class="xref py py-obj">m</em> and let <code class="docutils literal notranslate"><span class="pre">f</span> <span class="pre">=</span> <span class="pre">fweights</span></code> and <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">=</span> <span class="pre">aweights</span></code> for brevity. The
steps to compute the weighted covariance are as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span> <span class="o">**</span> <span class="mf">2.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ddof</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span> <span class="o">=</span> <span class="n">f</span> <span class="o">*</span> <span class="n">a</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">w</span> <span class="o">*</span> <span class="n">a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">-=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">m</span> <span class="o">*</span> <span class="n">w</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">/</span> <span class="n">v1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">m</span> <span class="o">*</span> <span class="n">w</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">*</span> <span class="n">v1</span> <span class="o">/</span> <span class="p">(</span><span class="n">v1</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="n">ddof</span> <span class="o">*</span> <span class="n">v2</span><span class="p">)</span>
</pre></div>
</div>
<p>Note that when <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">==</span> <span class="pre">1</span></code>, the normalization factor
<code class="docutils literal notranslate"><span class="pre">v1</span> <span class="pre">/</span> <span class="pre">(v1**2</span> <span class="pre">-</span> <span class="pre">ddof</span> <span class="pre">*</span> <span class="pre">v2)</span></code> goes over to <code class="docutils literal notranslate"><span class="pre">1</span> <span class="pre">/</span> <span class="pre">(np.sum(f)</span> <span class="pre">-</span> <span class="pre">ddof)</span></code>
as it should.</p>
<p class="rubric">Examples</p>
<p>Consider two variables, <span class="math notranslate nohighlight">\(x_0\)</span> and <span class="math notranslate nohighlight">\(x_1\)</span>, which
correlate perfectly, but in opposite directions:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span><span class="o">.</span><span class="n">T</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>
<span class="go">array([[0, 1, 2],</span>
<span class="go">       [2, 1, 0]])</span>
</pre></div>
</div>
<p>Note how <span class="math notranslate nohighlight">\(x_0\)</span> increases while <span class="math notranslate nohighlight">\(x_1\)</span> decreases. The covariance
matrix shows this clearly:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="go">array([[ 1., -1.],</span>
<span class="go">       [-1.,  1.]])</span>
</pre></div>
</div>
<p>Note that element <span class="math notranslate nohighlight">\(C_{0,1}\)</span>, which shows the correlation between
<span class="math notranslate nohighlight">\(x_0\)</span> and <span class="math notranslate nohighlight">\(x_1\)</span>, is negative.</p>
<p>Further, note how <em class="xref py py-obj">x</em> and <em class="xref py py-obj">y</em> are combined:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">2.1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>  <span class="mf">4.3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span>  <span class="mf">1.1</span><span class="p">,</span>  <span class="mf">0.12</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([[11.71      , -4.286     ], # may vary</span>
<span class="go">       [-4.286     ,  2.144133]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">array([[11.71      , -4.286     ], # may vary</span>
<span class="go">       [-4.286     ,  2.144133]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="go">array(11.71)</span>
</pre></div>
</div>
</dd></dl>

